# -*- coding: utf-8 -*-
import colorsys

import matplotlib.cm as cm
import matplotlib.colors as mcolors
import matplotlib.pyplot as plt
import networkx as nx
import numpy as np
import pandas as pd
import plotly
import plotly.graph_objs as go
from scipy import stats
from sklearn import decomposition
from sklearn.preprocessing import LabelEncoder, MinMaxScaler,maxabs_scale
from tmap.netx.SAFE import construct_node_data

class Color(object):
    """
    map colors to target values for TDA network visualization

    * If ``target_by`` set as *samples*, it means that it will pass original data instead of SAFE score for colorizing the node on the graph.
    * If ``node`` set as *node*, it means that it will pass SAFE score for colorizing the node on the graph. So the target must be a dictionary generated by SAFE_batch function. If you using single SAFE function called ``SAFE``, it will also create a dict which could be used.

    The basically code assign the highest values with red and the lowest values with blue. Before we assign the color, it will split the target into 4 parts with ``np.percentile`` and scale each part with different upper and lower boundary.

    It is normally have 4 distinct parts in color bar but it will easily missing some parts due to some skewness which misleading the values of percentile.


    :param list/np.ndarray/pd.Series/dict target: target values for samples or nodes
    :param str dtype: type of target values, "numerical" or "categorical"
    :param str target_by: target type of "sample" or "node"

    """

    def __init__(self, target, dtype="numerical", target_by="sample"):
        """
        :param list/np.ndarray/pd.Series target: target values for samples or nodes
        :param str dtype: type of target values, "numerical" or "categorical"
        :param str target_by: target type of "sample" or "node"
        (for node target values, accept a node associated dictionary of values)
        """
        if target is None:
            raise Exception("target must not be None.")

        # for node target values, accept a node associated dictionary of values
        if target_by == 'node':
            _target = np.zeros(len(target))
            for _node_idx, _node_val in target.items():
                _target[_node_idx] = _node_val
            target = _target

        if type(target) is not np.ndarray:
            target = np.array(target)
        if len(target.shape) == 1:
            target = target.reshape(-1, 1)
        if dtype not in ["numerical", "categorical"]:
            raise ValueError("data type must be 'numerical' or 'categorical'.")
        if target_by not in ["sample", "node"]:
            raise ValueError("target values must be by 'sample' or 'node'")
        # target values should be numbers, check and encode categorical labels

        if ((type(target[0][0]) != int)
                and (type(target[0][0]) != float)
                and (not isinstance(target[0][0], np.number))
        ):
            self.label_encoder = LabelEncoder()
            self.target = self.label_encoder.fit_transform(target)
        elif dtype == "categorical":
            self.label_encoder = LabelEncoder()
            self.target = self.label_encoder.fit_transform(target.astype(str))
        else:
            self.label_encoder = None
            self.target = target

        self.dtype = dtype
        self.labels = target
        self.target_by = target_by

    def _get_hex_color(self, i):
        """
        map a normalize i value to HSV colors
        :param i: input for the hue value, normalized to [0, 1.0]
        :return: a hex color code for i
        """
        # H values: from 0 (red) to 240 (blue), using the HSV color systems for color mapping
        # largest value of 1 mapped to red, and smallest of 0 mapped to blue
        c = colorsys.hsv_to_rgb((1 - i) * 240 / 360, 1.0, 0.75)
        return "#%02x%02x%02x" % (int(c[0] * 255), int(c[1] * 255), int(c[2] * 255))

    def _rescale_target(self, target):
        """
        scale target values according to density/percentile
        to make colors distributing evenly among values
        :param target: numerical target values
        :return:
        """
        rescaled_target = np.zeros(target.shape)

        scaler_min_q1 = MinMaxScaler(feature_range=(0, 0.25))
        scaler_q1_median = MinMaxScaler(feature_range=(0.25, 0.5))
        scaler_median_q3 = MinMaxScaler(feature_range=(0.5, 0.75))
        scaler_q3_max = MinMaxScaler(feature_range=(0.75, 1))

        q1, median, q3 = np.percentile(target, 25), np.percentile(target, 50), np.percentile(target, 75)


        index_min_q1 = np.where(target <= q1)[0]
        index_q1_median = np.where(((target >= q1) & (target <= median)))[0]
        index_median_q3 = np.where(((target >= median) & (target <= q3)))[0]
        index_q3_max = np.where(target >= q3)[0]

        target_min_q1 = scaler_min_q1.fit_transform(target[index_min_q1]) if any(index_min_q1) else np.zeros(target[index_min_q1].shape)
        target_q1_median = scaler_q1_median.fit_transform(target[index_q1_median]) if any(index_q1_median) else np.zeros(target[index_q1_median].shape)
        target_median_q3 = scaler_median_q3.fit_transform(target[index_median_q3]) if any(index_median_q3) else np.zeros(target[index_median_q3].shape)
        target_q3_max = scaler_q3_max.fit_transform(target[index_q3_max]) if any(index_q3_max) else np.zeros(target[index_q3_max].shape)
        # in case situation which will raise ValueError when sliced_index is all False.

        if all(target_q3_max == 0.75):
            target_q3_max = np.ones(target_q3_max.shape)
        if q1 == median == q3:
            target_q3_max = np.array([_ if _ != 0.75 else 0 for _ in target_q3_max[:, 0]]).reshape(target_q3_max.shape)
        rescaled_target[index_median_q3] = target_median_q3
        rescaled_target[index_q1_median] = target_q1_median
        rescaled_target[index_min_q1] = target_min_q1
        rescaled_target[index_q3_max] = target_q3_max

        return rescaled_target

    def get_colors(self, nodes, cmap=None):
        """
        :param dict nodes: nodes from graph
        :param cmap: not implemented yet...
        :return: nodes colors with keys, and the color map of the target values
        :rtype: tuple (first is a dict node_ID:node_color, second is a tuple (node_ID_index,node_color))
        """
        # todo: accept a customzied color map [via the 'cmap' parameter]
        node_keys = nodes.keys()

        # map a color for each node
        node_color_idx = np.zeros((len(nodes), 1))
        for i, node_id in enumerate(node_keys):
            if self.target_by == 'node':
                target_in_node = self.target[node_id]
            else:
                target_in_node = self.target[nodes[node_id]]

            # summarize target values from samples/nodes for each node
            if self.dtype == "categorical":
                # most common value (if more than one, the smallest is return)
                node_color_idx[i] = stats.mode(target_in_node)[0][0]
            elif self.dtype == "numerical":
                node_color_idx[i] = np.nanmean(target_in_node)
        if np.any(np.isnan(node_color_idx)):
            print("Nan was found in the given target, Please check the input data.")
        _node_color_idx = self._rescale_target(node_color_idx)
        node_colors = [self._get_hex_color(idx) for idx in _node_color_idx]

        return dict(zip(node_keys, node_colors)), (node_color_idx, node_colors)

    def get_sample_colors(self, cmap=None):
        """
        :param dict nodes: nodes from graph
        :param cmap: not implemented yet...
        :return: nodes colors with keys, and the color map of the target values
        :rtype: tuple (first is a dict node_ID:node_color, second is a tuple (node_ID_index,node_color))
        """
        # todo: accept a customzied color map [via the 'cmap' parameter]
        if self.target_by != "sample":
            raise IOError
        if self.dtype == "numerical":
            _sample_color_idx = self._rescale_target(self.target)
        else:
            _sample_color_idx = self._rescale_target(self.target.reshape(-1,1))
        sample_colors = [self._get_hex_color(idx) for idx in _sample_color_idx]

        return sample_colors


def show(data, graph, color=None, fig_size=(10, 10), node_size=10, edge_width=2, mode=None, strength=None):
    """
    Network visualization of TDA mapper

    Using matplotlib as basic engine, it is easily add title or others elements.

    :param np.ndarray/pd.DataFrame data:
    :param dict graph:
    :param Color/str color: Passing ``tmap.tda.plot.Color`` or just simply color string.
    :param tuple fig_size: height and width
    :param int node_size: With given node_size, it will scale all nodes with same size ``node_size/max(node_sizes) * node_size **2``. The size of nodes also depends on the biggest node which contains maxium number of samples.
    :param int edge_width: Line width of edges.
    :param str/None mode: Currently, Spring layout is the only one style supported.
    :param float strength: Optimal distance between nodes.  If None the distance is set to ``1/sqrt(n)`` where n is the number of nodes.  Increase this value to move nodes farther apart.
    :return: plt.figure
    """
    # todo: add file path for graph saving
    node_keys = graph["node_keys"]
    node_positions = graph["node_positions"]
    node_sizes = graph["node_sizes"]

    # scale node sizes
    max_node_size = np.max(node_sizes)
    sizes = (node_sizes / max_node_size) * (node_size ** 2)

    # map node colors
    if color is None or type(color) == str:
        if color is None:
            color = 'red'
        color_map = {node_id: color for node_id in node_keys}
        target2colors = (np.zeros((len(node_keys), 1)), [color] * len(node_keys))
    else:
        color_map, target2colors = color.get_colors(graph["nodes"])
    colorlist = [color_map[it] for it in node_keys]

    fig = plt.figure(figsize=fig_size)
    ax = fig.add_subplot(1, 1, 1)

    node_target_values, node_colors = target2colors
    legend_lookup = dict(zip(node_target_values.reshape(-1, ), node_colors))

    # add categorical legend
    if isinstance(color, Color):
        if color.dtype == "categorical":
            for label in set([it[0] for it in color.labels]):
                if color.label_encoder:
                    label_color = legend_lookup.get(color.label_encoder.transform([label])[0], None)
                else:
                    label_color = legend_lookup.get(label, None)
                if label_color is not None:
                    ax.plot([], [], 'o', color=label_color, label=label, markersize=10)
            legend = ax.legend(numpoints=1, loc="upper right")
            legend.get_frame().set_facecolor('#bebebe')

        # add numerical colorbar
        elif color.dtype == "numerical":
            legend_values = sorted([_ for _ in legend_lookup])
            legned_colors = [legend_lookup[_] for _ in legend_values]

            cmap = mcolors.LinearSegmentedColormap.from_list('my_cmap', legned_colors)
            norm = mcolors.Normalize(min(legend_values), max(legend_values))
            sm = cm.ScalarMappable(cmap=cmap, norm=norm)
            sm.set_array([])

            cb = fig.colorbar(sm, shrink=0.5)
            cb.ax.yaxis.set_ticks_position('right')
            if min(legend_values) != 0:
                if min(legend_values) * 100 >= 0.1:
                    cb.ax.text(0.5, -0.02, '{:.2f}'.format(min(legend_values)), ha='center', va='top', weight='bold')
                else:
                    cb.ax.text(0.5, -0.02, '{:.2e}'.format(min(legend_values)), ha='center', va='top', weight='bold')
            if max(legend_values) * 100 >= 0.1:
                cb.ax.text(0.5, 1.02, '{:.2f}'.format(max(legend_values)), ha='center', va='bottom', weight='bold')
            else:
                cb.ax.text(0.5, 1.02, '{:.2e}'.format(max(legend_values)), ha='center', va='bottom', weight='bold')

    if mode == 'spring':
        pos = {}
        # the projection space is one dimensional
        if node_positions.shape[1] == 1:
            m = decomposition.PCA(n_components=2)
            s = MinMaxScaler()
            d = m.fit_transform(data)
            d = s.fit_transform(d)
            for k in node_keys:
                data_in_node = d[graph['nodes'][k]]
                pos.update({int(k): np.average(data_in_node, axis=0)})
        elif node_positions.shape[1] >= 2:
            for i, k in enumerate(node_keys):
                pos.update({int(k): node_positions[i, :2]})

        G = nx.Graph(pos=pos)
        G.add_nodes_from(node_keys)
        G.add_edges_from(graph["edges"])
        pos = nx.spring_layout(G, pos=pos, k=strength)
        # add legend
        nx.draw_networkx(G, pos=pos, node_size=sizes,
                         node_color=colorlist,
                         width=edge_width,
                         edge_color=[color_map[edge[0]] for edge in graph["edges"]],
                         with_labels=False, label="0", ax=ax)

    else:
        fig = plt.figure(figsize=fig_size)
        ax = fig.add_subplot(111)
        node_idx = dict(zip(node_keys, range(len(node_keys))))
        for edge in graph["edges"]:
            ax.plot([node_positions[node_idx[edge[0]], 0], node_positions[node_idx[edge[1]], 0]],
                    [node_positions[node_idx[edge[0]], 1], node_positions[node_idx[edge[1]], 1]],
                    c=color_map[edge[0]], zorder=1)
        ax.scatter(node_positions[:, 0], node_positions[:, 1],
                   c=colorlist, s=sizes, zorder=2)

    plt.axis("off")
    plt.show()


def get_arrows(graph, projected_X, safe_score, max_length=1,pvalue=0.05):
    min_p_value = 1.0 / (5000 + 1.0)
    threshold = np.log10(pvalue) / np.log10(min_p_value)

    node_pos = construct_node_data(graph, projected_X)

    safe_score_df = pd.DataFrame.from_dict(safe_score, orient='columns')
    safe_score_df = safe_score_df.where(safe_score_df>=threshold,other=0)
    norm_df = safe_score_df.apply(lambda x: maxabs_scale(x), axis=1, result_type='broadcast')

    x_cor = norm_df.apply(lambda x: x * node_pos.values[:, 0], axis=0)
    y_cor = norm_df.apply(lambda x: x * node_pos.values[:, 1], axis=0)

    x_cor = x_cor.mean(0)
    y_cor = y_cor.mean(0)
    arrow_df = pd.DataFrame([x_cor, y_cor], index=['x coordinate', 'y coordinate'], columns=safe_score_df.columns)
    all_fea_scale = maxabs_scale(safe_score_df.sum(0))
    # scale each arrow by the sum of safe scoreï¼Œ maximun is 1 others are percentage not larger than 100%.
    scaled_ratio = max_length * all_fea_scale / arrow_df.apply(lambda x: np.sqrt(np.sum(x ** 2)), axis=0)
    # using max length to multipy by scale ratio and denote the original length.
    scaled_arrow_df = arrow_df * np.repeat(scaled_ratio.values.reshape(1, -1), axis=0, repeats=2).reshape(2, -1)

    return scaled_arrow_df

def vis_progressX(graph, projected_X, simple=False,mode='file', color=None,_color_SAFE=None, **kwargs):
    """

    :param graph:
    :param projected_X:
    :param filepath:
    :param color:
    :param _color_SAFE:
    :param kwargs:
    :return:
    """
    node_pos = graph["node_positions"]
    ori_MDS = MinMaxScaler().fit_transform(projected_X)
    nodes = graph["nodes"]
    sizes = graph["node_sizes"][:,0]

    if color:
        color_map, target2colors = color.get_colors(graph["nodes"])
    else:
        color = Color([0] * projected_X.shape[0])

    if color.target_by == "node":
        samples_colors = "red"
    else:
        samples_colors = color.get_sample_colors()

    # For calculating the dynamic process.
    # reordering the ori_MDS into the point_pos
    # reshaping the node_pos into the center_pos
    point_tmp = []
    center_tmp = []
    samples_colors_dynamic = []
    for n in nodes:
        point_tmp.append(ori_MDS[nodes[n], :])
        center_tmp.append(np.concatenate([node_pos[[n], :]] * len(nodes[n]), axis=0))
        if color:
            samples_colors_dynamic += list(np.repeat(color_map[n], len(nodes[n])))
        else:
            samples_colors_dynamic.append("blue")
    samples_pos = np.concatenate(point_tmp, axis=0)
    center_pos = np.concatenate(center_tmp, axis=0)

    node_pos = graph["node_positions"]
    # init edge plot data
    xs = []
    ys = []
    for edge in graph["edges"]:
        xs += [node_pos[edge[0], 0],
               node_pos[edge[1], 0],
               None]
        ys += [node_pos[edge[0], 1],
               node_pos[edge[1], 1],
               None]
    # init text data for each node
    if color.target_by == "sample":
        _text = [str(n) + "<Br>%s<Br>" % str(np.mean(color.target[nodes[n], 0])) + '<Br>'.join(np.array(graph.get("sample_names")).astype(str)[graph["nodes"][n]]) for n in
                 graph["nodes"]]
    else:
        _text = [str(n) + "<Br>%s<Br>" % str(color.target[n]) + '<Br>'.join(np.array(graph.get("sample_names")).astype(str)[graph["nodes"][n]]) for n in
                 graph["nodes"]]
    # if there are _color_SAFE, it will present two kinds of color.
    # one is base on original data, one is transformed-SAFE data.
    if _color_SAFE is not None:
        safe_color, safe_t2c = _color_SAFE.get_colors(graph["nodes"])
        node_colors = [safe_color[_] for _ in range(len(nodes))]
    else:
        node_colors = [color_map[_] for _ in range(len(nodes))]

    node_line = go.Scatter(
        # ordination line
        visible=False,
        x=xs,
        y=ys,
        marker=dict(color="#8E9DA2",
                    opacity=0.7),
        line=dict(width=1),
        showlegend=False,
        mode="lines")
    node_position = go.Scatter(
        # node position
        visible=False,
        x=node_pos[:, 0],
        y=node_pos[:, 1],
        text=_text,
        hoverinfo="text",
        marker=dict(color=node_colors,
                    size=[5 + sizes[_] for _ in range(len(nodes))],
                    opacity=1),
        showlegend=False,
        mode="markers")
    samples_position = go.Scatter(
        visible=True,
        x=ori_MDS[:, 0],
        y=ori_MDS[:, 1],
        marker=dict(color=samples_colors),
        text=graph.get("sample_names"),
        hoverinfo="text",
        showlegend=False,
        mode="markers")

    if simple:
        fig = plotly.tools.make_subplots(1,1)
        node_line['visible'] = True
        node_position['visible'] = True
        fig.append_trace(node_line, 1, 1)
        fig.append_trace(node_position, 1,1)

    else:
        fig = plotly.tools.make_subplots(rows=2, cols=2, specs=[[{'rowspan': 2}, {}], [None, {}]],
                                         # subplot_titles=('Mapping process', 'Original projection', 'tmap graph')
                                         )
        # original place or ordination place
        fig.append_trace(samples_position, 1, 1)

        # dynamic process to generate 10 binning positions
        steps = 10
        for s in range(steps + 1):
            fig.append_trace(go.Scatter(
                visible=False,
                x=samples_pos[:, 0] + ((center_pos - samples_pos) / steps * s)[:, 0],
                y=samples_pos[:, 1] + ((center_pos - samples_pos) / steps * s)[:, 1],
                marker=dict(color=samples_colors_dynamic),
                showlegend=False,
                mode="markers"), 1, 1)
        # to node positions

        # order is important, do not change the order !!!
        fig.append_trace(node_line, 1, 1)
        fig.append_trace(node_position, 1, 1)
        node_line['visible'] = True
        node_position['visible'] = True
        samples_position['visible'] = True
        fig.append_trace(node_line, 2, 2)
        fig.append_trace(node_position, 2, 2)

        fig.append_trace(samples_position, 1, 2)
        ############################################################
        steps = []
        for i in range(14):
            step = dict(
                method='restyle',
                args=['visible', [False] * 14 + [True, True, True]],
            )
            if i >= 12:
                step["args"][1][-5:] = [True] * 5
            else:
                step['args'][1][i] = True  # Toggle i'th trace to "visible"
            steps.append(step)

        sliders = [dict(
            active=0,
            currentvalue={"prefix": "status: "},
            pad={"t": 14},
            steps=steps
        )]
        ############################################################
        layout = dict(sliders=sliders,
                      width=2000,
                      height=1000,
                      xaxis1={"range": [0, 1], "domain": [0, 0.5]},
                      yaxis1={"range": [0, 1], "domain": [0, 1]},
                      xaxis2={"range": [0, 1], "domain": [0.6, 0.9]},
                      yaxis2={"range": [0, 1], "domain": [0.5, 1]},
                      xaxis3={"range": [0, 1], "domain": [0.6, 0.9]},
                      yaxis3={"range": [0, 1], "domain": [0, 0.5]},
                      hovermode="closest"
                      )
        fig.layout.update(layout)

    if mode == 'file':
        plotly.offline.plot(fig, **kwargs)

    elif mode == 'web':
        plotly.offline.iplot(fig, **kwargs)
    elif mode == 'obj':
        return fig
    else:
        print("mode params must be one of 'file', 'web', 'obj'. \n 'file': output html file \n 'web': show in web browser. \n 'obj': return a dict object.")


def draw_stats_plot(graph,safe_score,fea, metainfo,_filter_size=0,**kwargs):
    """

    Draw simple node network which only show component which is larger than _filter_size and colorized with
    its safe_score.

    :param graph:
    :param safe_score:
    :param fea:
    :param metainfo:
    :param _filter_size:
    :param kwargs:
    :return:
    """
    enriched_nodes, comps_nodes = metainfo[fea]

    node_pos = graph["node_positions"]
    sizes = graph["node_sizes"][:, 0]
    fig = plotly.tools.make_subplots(1, 1)
    xs = []
    ys = []

    for edge in graph["edges"]:
        xs += [node_pos[edge[0], 0],
               node_pos[edge[1], 0],
               None]
        ys += [node_pos[edge[0], 1],
               node_pos[edge[1], 1],
               None]

    node_line = go.Scatter(
        # ordination line
        visible=True,
        x=xs,
        y=ys,
        hoverinfo='none',
        marker=dict(color="#8E9DA2", ),
        line=dict(width=1),
        showlegend=False,
        mode="lines")

    fig.append_trace(node_line, 1, 1)

    for idx, nodes in enumerate(comps_nodes):
        if _filter_size:
            if len(nodes) <= _filter_size:
                continue
        tmp1 = {k: v if k in nodes else np.nan for k, v in safe_score[fea].items()}
        node_position = go.Scatter(
            # node position
            visible=True,
            x=node_pos[[k for k, v in safe_score[fea].items() if not np.isnan(tmp1[k])], 0],
            y=node_pos[[k for k, v in safe_score[fea].items() if not np.isnan(tmp1[k])], 1],
            hoverinfo="text",
            text=['node:%s,SAFE:%s' % (k, safe_score[fea][k]) for k, v in safe_score[fea].items() if not np.isnan(tmp1[k])],
            marker=dict(  # color=node_colors,
                size=[7 + sizes[_] for _ in [k for k, v in safe_score[fea].items() if not np.isnan(tmp1[k])]],
                opacity=0.8),
            showlegend=True,
            name='comps_%s' % idx,
            mode="markers")
        fig.append_trace(node_position, 1, 1)

    fig.layout.font.size = 15
    fig.layout.title = fea
    fig.layout.height = 1500
    fig.layout.width = 1500
    fig.layout.hovermode = 'closest'
    plotly.offline.plot(fig,**kwargs)
